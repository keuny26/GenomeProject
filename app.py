import streamlit as st
import fitz  # PyMuPDF
import json
import re
import time
import google.generativeai as genai
from streamlit_agraph import agraph, Node, Edge, Config
from Bio import Entrez  # NCBI ì—°ë™ìš©

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="GenomeGraph AI", layout="wide")
st.title("ğŸ§¬ GenomeGraph AI (Final Stable Version)")

# --- 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state: st.session_state.messages = []
if "full_text" not in st.session_state: st.session_state.full_text = ""
if "graph_data" not in st.session_state: st.session_state.graph_data = None

# --- 3. API í‚¤ ë° ì„¤ì • (ì‚¬ì´ë“œë°”) ---
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì • ë° ë³´ì•ˆ")
    # GitHub Secrets ì‚¬ìš© ê¶Œì¥
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.info("âœ… Secretsì—ì„œ API í‚¤ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    else:
        api_key = st.text_input("Gemini API Key", type="password", help="GitHub Secrets ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    ncbi_email = st.text_input("NCBI ì—°ë™ìš© ì´ë©”ì¼", value="your_email@example.com")
    
    if st.button("ğŸ—‘ï¸ ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# --- 4. ëª¨ë¸ ë° NCBI í•¨ìˆ˜ ---
model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        # 404 ì—ëŸ¬ ë°©ì§€: ëª¨ë¸ ì´ë¦„ë§Œ ëª…í™•íˆ ì „ë‹¬
        model = genai.GenerativeModel(model_name='gemini-1.5-flash')
        st.sidebar.success("ëª¨ë¸ ì—°ê²°ë¨: gemini-1.5-flash")
    except Exception as e:
        st.error(f"ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜: {e}")

def get_ncbi_gene_info(gene_name, email):
    Entrez.email = email
    try:
        search_handle = Entrez.esearch(db="gene", term=f"{gene_name}[Gene Name] AND human[Organism]")
        search_results = Entrez.read(search_handle)
        if not search_results["IdList"]: return "NCBI ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        gene_id = search_results["IdList"][0]
        summary_handle = Entrez.esummary(db="gene", id=gene_id)
        summary_record = Entrez.read(summary_handle)
        return summary_record['DocumentSummarySet']['DocumentSummary'][0]['Description']
    except: return "NCBI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨"

# --- 5. ë¶„ì„ ë° ë³‘í•© ë¡œì§ ---
def analyze_single_doc(text, filename):
    if not model: return None
    # ë³´ì•ˆ: ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ (ì „í™”ë²ˆí˜¸ í˜•íƒœ ë“±)
    clean_text = re.sub(r'\d{3}-\d{4}-\d{4}', "[PROTECTED]", text)
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ìœ ì „ì²´ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ìœ ì „ì(Gene), ì§ˆí™˜/ì¦ìƒ(Disease), ë³€ì´(Variant) ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    - ì¦ìƒ/ì§ˆë³‘ì€ ë°˜ë“œì‹œ 'type': 'Disease'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    - ì¶œë ¥ í˜•ì‹: {{"nodes": [{{"id": "ID", "label": "ì´ë¦„", "type": "Gene/Disease/Variant", "desc": "ì„¤ëª…"}}], "links": [{{"source": "ID", "target": "ID"}}]}}
    í…ìŠ¤íŠ¸: {clean_text[:12000]}
    """
    
    try:
        time.sleep(1) # API í• ë‹¹ëŸ‰ ê´€ë¦¬
        response = model.generate_content(prompt)
        # JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
        json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if json_match:
            data = json.loads(json_match.group())
            # ë…¸ë“œë³„ ì¶œì²˜ ì •ë³´ ê¸°ë¡
            for n in data.get('nodes', []): n['source_file'] = filename
            return data
        return None
    except Exception as e:
        st.error(f"{filename} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def merge_graphs(results):
    merged_nodes = {}
    merged_links = []
    for data in results:
        if not data: continue
        for n in data.get('nodes', []):
            nid = n['id']
            if nid in merged_nodes:
                merged_nodes[nid]['source_file'] = "Common"
            else:
                merged_nodes[nid] = n
        merged_links.extend(data.get('links', []))
    
    # ì¤‘ë³µ ë§í¬ ì œê±°
    unique_links = [dict(t) for t in {tuple(sorted(d.items())) for d in merged_links}]
    return {"nodes": list(merged_nodes.values()), "links": unique_links}

# --- 6. UI: íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ---
uploaded_files = st.file_uploader("ë¶„ì„í•  PDF ë³´ê³ ì„œë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf", accept_multiple_files=True)

if uploaded_files and api_key:
    if st.button("ğŸ§¬ í†µí•© ë¶„ì„ ì‹œì‘ (Multi-Doc Mode)"):
        all_results = []
        with st.spinner("ë¬¸ì„œë³„ ì •ë°€ ë¶„ì„ ì§„í–‰ ì¤‘..."):
            full_text_accumulator = ""
            for uploaded_file in uploaded_files:
                doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                text = " ".join([page.get_text() for page in doc])
                full_text_accumulator += f"\n\n[Document: {uploaded_file.name}]\n{text}"
                
                res = analyze_single_doc(text, uploaded_file.name)
                all_results.append(res)
            
            st.session_state.full_text = full_text_accumulator
            st.session_state.graph_data = merge_graphs(all_results)
            st.session_state.messages = []
            st.success("í†µí•© ë¶„ì„ ì™„ë£Œ!")

    # --- 7. ê·¸ë˜í”„ ì‹œê°í™” ì˜ì—­ ---
    if st.session_state.graph_data:
        st.sidebar.divider()
        st.sidebar.subheader("ğŸ” í•„í„°ë§")
        all_types = list(set([n.get('type', 'Unknown') for n in st.session_state.graph_data['nodes']]))
        selected_types = st.sidebar.multiselect("í‘œì‹œí•  íƒ€ì…", all_types, default=all_types)
        search_query = st.sidebar.text_input("ğŸ¯ ë…¸ë“œ ê²€ìƒ‰")

        col1, col2 = st.columns([3, 1])
        
        # NameError ë°©ì§€: selected_id ì´ˆê¸°í™”
        selected_id = None
        
        # íŒŒì¼ë³„ ì»¬ëŸ¬ ë§µí•‘
        file_names = [f.name for f in uploaded_files]
        color_palette = ["#4285F4", "#34A853", "#FBBC05", "#8E44AD", "#F39C12", "#16A085"]
        color_map = {name: color_palette[i % len(color_palette)] for i, name in enumerate(file_names)}
        color_map["Common"] = "#EA4335" 

        with col1:
            filtered_nodes = []
            filtered_node_ids = set()
            for n in st.session_state.graph_data['nodes']:
                if n.get('type') in selected_types and search_query.lower() in n.get('label', '').lower():
                    src = n.get('source_file', 'Unknown')
                    n_color = color_map.get(src, "#999999")
                    is_common = src == "Common"
                    filtered_nodes.append(Node(id=n['id'], 
                                               label=f"â­ {n['label']}" if is_common else n['label'], 
                                               size=35 if is_common else 25, 
                                               color=n_color))
                    filtered_node_ids.add(n['id'])
            
            filtered_edges = [Edge(source=l['source'], target=l['target']) 
                              for l in st.session_state.graph_data['links'] 
                              if l['source'] in filtered_node_ids and l['target'] in filtered_node_ids]

            if filtered_nodes:
                config = Config(width=900, height=600, directed=True, physics=True, fit_view=True)
                selected_id = agraph(nodes=filtered_nodes, edges=filtered_edges, config=config)

        with col2:
            st.markdown("### ğŸ¨ ë²”ë¡€")
            for src, color in color_map.items():
                st.markdown(f"<span style='color:{color}'>â—</span> **{src}**", unsafe_allow_html=True)
            
            st.divider()
            if selected_id:
                node_detail = next((n for n in st.session_state.graph_data['nodes'] if str(n['id']) == str(selected_id)), None)
                if node_detail:
                    st.success(f"**ì´ë¦„:** {node_detail['label']}")
                    st.info(f"**íƒ€ì…:** {node_detail['type']} | **ì¶œì²˜:** {node_detail.get('source_file')}")
                    
                    if node_detail['type'] == "Gene":
                        with st.spinner("NCBI ë°ì´í„° ê²€ìƒ‰ ì¤‘..."):
                            ncbi_info = get_ncbi_gene_info(node_detail['label'], ncbi_email)
                            st.caption(f"**NCBI Summary:** {ncbi_info}")
                    
                    st.link_button("ğŸ§¬ NCBI ìƒì„¸ë³´ê¸°", f"https://www.ncbi.nlm.nih.gov/gene/?term={node_detail['label']}")
                    st.write(f"**ìƒì„¸ ì„¤ëª…:**\n{node_detail.get('desc', 'ë‚´ìš© ì—†ìŒ')}")
            else:
                st.info("ê·¸ë˜í”„ ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# --- 8. ì±„íŒ… ì˜ì—­ ---
if st.session_state.full_text:
    st.divider()
    st.subheader("ğŸ’¬ ë¶„ì„ ë°ì´í„° ê¸°ë°˜ Q&A")
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])

    if chat_prompt := st.chat_input("ì´ ìœ ì „ì²´ ë°ì´í„°ë“¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": chat_prompt})
        with st.chat_message("user"): st.markdown(chat_prompt)
        
        with st.chat_message("assistant"):
            try:
                # 404 ë°©ì§€ë¥¼ ìœ„í•´ ì´ˆê¸°í™”ëœ model ê°ì²´ ì‚¬ìš©
                res = model.generate_content(f"Context: {st.session_state.full_text[:10000]}\nQuestion: {chat_prompt}")
                st.markdown(res.text)
                st.session_state.messages.append({"role": "assistant", "content": res.text})
            except Exception as e:
                st.error(f"ì±„íŒ… ì‘ë‹µ ì˜¤ë¥˜: {e}")