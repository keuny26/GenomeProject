import streamlit as st
import fitz  # PyMuPDF
import json
import re
import google.generativeai as genai
from streamlit_agraph import agraph, Node, Edge, Config

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="GenomeGraph AI", layout="wide")
st.title("ğŸ§¬ GenomeGraph AI (Streamlit)")

# --- API í‚¤ ì„¤ì • ---
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    st.sidebar.title("ì„¤ì •")
    api_key = st.sidebar.text_input("Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

# --- ëª¨ë¸ ì´ˆê¸°í™” ---
model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        target_model = 'gemini-1.5-flash'
        if f'models/{target_model}' in available_models:
            model = genai.GenerativeModel(target_model)
        elif available_models:
            model = genai.GenerativeModel(available_models[0].replace('models/', ''))
        
        if model:
            st.sidebar.success(f"ì—°ê²°ë¨: {model.model_name}")
    except Exception as e:
        st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")

# --- ë¶„ì„ í•¨ìˆ˜ (ê·¸ë˜í”„ ë°ì´í„° ìƒì„±) ---
def analyze_graph_with_ai(text):
    if not model: return None
    prompt = f"""
    ë‹¹ì‹ ì€ ìœ ì „ì²´ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ìœ ì „ìì™€ ì§ˆí™˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    ê° ë…¸ë“œì—ëŠ” ë°˜ë“œì‹œ 'desc'(ìƒì„¸ ì„¤ëª…) í•„ë“œë¥¼ í¬í•¨ì‹œì¼œì£¼ì„¸ìš”.

    í˜•ì‹:
    {{
      "nodes": [{{ "id": "ID", "label": "ì´ë¦„", "type": "gene/disease", "desc": "ìƒì„¸ ë¶„ì„ ë‚´ìš©" }}],
      "links": [{{ "source": "ID", "target": "ID" }}]
    }}
    í…ìŠ¤íŠ¸: {text[:10000]}
    """
    try:
        response = model.generate_content(prompt)
        json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
        return json.loads(json_match.group()) if json_match else None
    except: return None

# --- ë©”ì¸ UI ---
uploaded_file = st.file_uploader("PDF ë³´ê³ ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file and api_key:
    # 1. ë°ì´í„° ë¡œë“œ (ì„¸ì…˜ ìƒíƒœ ì €ì¥)
    if "full_text" not in st.session_state:
        with st.spinner("PDF ë¶„ì„ ì¤‘..."):
            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            st.session_state.full_text = " ".join([page.get_text() for page in doc])
            st.session_state.graph_data = analyze_graph_with_ai(st.session_state.full_text)
            st.session_state.messages = [] # ì±„íŒ… ì´ˆê¸°í™”

    # 2. ê·¸ë˜í”„ ë° ìƒì„¸ ì •ë³´ ë ˆì´ì•„ì›ƒ
    if st.session_state.get("graph_data"):
        st.subheader("ğŸ§¬ ìœ ì „ì²´ ì§€ì‹ ê·¸ë˜í”„ ë° ìƒì„¸ ì •ë³´")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            nodes = [Node(id=n['id'], label=n['label'], size=20, color=('#4285F4' if n.get('type') == 'gene' else '#EA4335')) 
                     for n in st.session_state.graph_data.get('nodes', [])]
            edges = [Edge(source=l['source'], target=l['target']) for l in st.session_state.graph_data.get('links', [])]
            
            config = Config(width=800, height=500, directed=True, physics=True)
            # ë…¸ë“œ í´ë¦­ ì‹œ selected_idì— í•´ë‹¹ ë…¸ë“œì˜ IDê°€ ì €ì¥ë¨
            selected_id = agraph(nodes=nodes, edges=edges, config=config)

        with col2:
            st.markdown("### ğŸ” ìƒì„¸ ì •ë³´")
            if selected_id:
                # ì„ íƒëœ ë…¸ë“œ ì°¾ê¸°
                node_detail = next((n for n in st.session_state.graph_data['nodes'] if n['id'] == selected_id), None)
                if node_detail:
                    st.success(f"**ëª…ì¹­:** {node_detail['label']}")
                    st.info(f"**ì„¤ëª…:** {node_detail.get('desc', 'ì´ ë…¸ë“œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.')}")
                else:
                    st.warning("ë°ì´í„° ë™ê¸°í™” ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
            else:
                st.write("ğŸ’¡ ê·¸ë˜í”„ì˜ ë™ê·¸ë¼ë¯¸(ë…¸ë“œ)ë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ë¶„ì„ ë‚´ìš©ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    st.divider()

    # 3. AI ì±„íŒ…ì°½ ì˜ì—­
    st.subheader("ğŸ’¬ AI ë¶„ì„ê°€ì™€ ëŒ€í™”í•˜ê¸°")
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = model.generate_content(f"ë¬¸ì„œ ë‚´ìš©: {st.session_state.full_text[:8000]}\n\nì§ˆë¬¸: {prompt}")
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})