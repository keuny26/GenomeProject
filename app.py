import streamlit as st
import fitz  # PyMuPDF
import json
import re
import google.generativeai as genai
from streamlit_agraph import agraph, Node, Edge, Config

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="GenomeGraph AI", layout="wide")
st.title("ğŸ§¬ GenomeGraph AI (Smart Integration)")

# --- API í‚¤ ì„¤ì • ---
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    st.sidebar.title("ì„¤ì •")
    api_key = st.sidebar.text_input("Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

# --- ëª¨ë¸ ì´ˆê¸°í™” ---
model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target_model = 'gemini-1.5-flash'
        if f'models/{target_model}' in available_models:
            model = genai.GenerativeModel(target_model)
        elif available_models:
            model = genai.GenerativeModel(available_models[0].replace('models/', ''))
        
        if model:
            st.sidebar.success(f"ì—°ê²°ë¨: {model.model_name}")
    except Exception as e:
        st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")

# --- ë¶„ì„ í•¨ìˆ˜ (ë©€í‹° íŒŒì¼ í†µí•© ìµœì í™”) ---
def analyze_graph_with_ai(text):
    if not model: return None
    
    # 2ê°œ ì´ìƒì˜ ë¬¸ì„œë¥¼ ëª¨ë‘ ì½ë„ë¡ í•˜ëŠ” ê°•ë ¥í•œ ì§€ì‹œì‚¬í•­
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ìœ ì „ì²´ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ í…ìŠ¤íŠ¸ëŠ” ì—¬ëŸ¬ ê°œì˜ ìœ ì „ì²´ ë³´ê³ ì„œê°€ í†µí•©ëœ ë‚´ìš©ì…ë‹ˆë‹¤.

    [ì‘ì—… ëª©í‘œ]
    1. **ëª¨ë“  ë¬¸ì„œ í¬í•¨**: ì œê³µëœ ëª¨ë“  í…ìŠ¤íŠ¸([Document: íŒŒì¼ëª…] íƒœê·¸ë¡œ êµ¬ë¶„ë¨)ë¥¼ í›‘ì–´ë³´ê³  ê° ë¬¸ì„œì˜ ìœ ì „ì-ì§ˆí™˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    2. **í†µí•© ë° ì—°ê²°**: ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ê³µí†µìœ¼ë¡œ ë“±ì¥í•˜ëŠ” ë…¸ë“œëŠ” í•˜ë‚˜ë¡œ í•©ì¹˜ê³ , ê° ë¬¸ì„œì˜ ë¶„ì„ ë‚´ìš©ì„ 'desc' í•„ë“œì— ì¢…í•©í•˜ì„¸ìš”.
    3. **JSON ì¶œë ¥**: ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡°ë¥¼ ì§€í‚¨ JSON ë°ì´í„°ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

    {{
      "nodes": [
        {{ "id": "unique_id", "label": "ìœ ì „ì/ì§ˆí™˜ëª…", "type": "gene ë˜ëŠ” disease", "desc": "ìƒì„¸ ë‚´ìš© ìš”ì•½" }}
      ],
      "links": [
        {{ "source": "node_id", "target": "node_id" }}
      ]
    }}

    í…ìŠ¤íŠ¸ (ìµœëŒ€ 20,000ì):
    {text[:20000]}
    """
    
    try:
        response = model.generate_content(prompt)
        # JSON ë¸”ë¡ë§Œ ì¶”ì¶œí•˜ëŠ” ì •ê·œí‘œí˜„ì‹
        json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        return None
    except Exception as e:
        if "429" in str(e):
            st.error("API í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì•½ 1ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --- ë©”ì¸ UI: ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ---
uploaded_files = st.file_uploader("PDF ë³´ê³ ì„œë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf", accept_multiple_files=True)

if uploaded_files and api_key:
    # ì¿¼í„° ë³´í˜¸ë¥¼ ìœ„í•œ ë¶„ì„ ì‹œì‘ ë²„íŠ¼
    if st.button("ğŸ§¬ í†µí•© ë¶„ì„ ì‹œì‘ (API í˜¸ì¶œ)"):
        with st.spinner("ì—¬ëŸ¬ ë¬¸ì„œì˜ ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            combined_text = ""
            for uploaded_file in uploaded_files:
                doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                # ê° ë¬¸ì„œì˜ ì‹œì‘ì„ì„ AIì—ê²Œ ì•Œë¦¼
                combined_text += f"\n\n[Document: {uploaded_file.name}]\n"
                combined_text += " ".join([page.get_text() for page in doc])
            
            st.session_state.full_text = combined_text
            st.session_state.last_files = [f.name for f in uploaded_files]
            # AI ë¶„ì„ í˜¸ì¶œ
            st.session_state.graph_data = analyze_graph_with_ai(st.session_state.full_text)
            st.session_state.messages = []
            
            if st.session_state.graph_data:
                st.success(f"ì„±ê³µ: {len(uploaded_files)}ê°œì˜ íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
            else:
                st.error("AIê°€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # 2. ê·¸ë˜í”„ ì˜ì—­
    if st.session_state.get("graph_data"):
        st.subheader("ğŸ§¬ í†µí•© ì§€ì‹ ê·¸ë˜í”„")
        st.info("ğŸ’¡ ì¤Œì¸/ì•„ì›ƒì´ ê°€ëŠ¥í•˜ë©°, ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            nodes = []
            raw_nodes = st.session_state.graph_data.get('nodes', [])
            for n in raw_nodes:
                if 'id' in n:
                    l_text = n.get('label', n['id'])
                    n_type = n.get('type', '').lower()
                    # ìœ ì „ìëŠ” íŒŒë€ìƒ‰, ì§ˆí™˜ì€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ êµ¬ë¶„
                    n_color = '#4285F4' if 'gene' in n_type else '#EA4335'
                    nodes.append(Node(id=n['id'], label=l_text, size=25, color=n_color))
            
            edges = []
            raw_links = st.session_state.graph_data.get('links', [])
            for l in raw_links:
                if 'source' in l and 'target' in l:
                    edges.append(Edge(source=l['source'], target=l['target']))

            if nodes:
                # fit_view=Trueë¡œ ì„¤ì •í•˜ì—¬ í•­ìƒ ê·¸ë˜í”„ê°€ ì¤‘ì•™ì— ì˜¤ë„ë¡ í•¨
                config = Config(
                    width=900, 
                    height=600, 
                    directed=True, 
                    physics=True, 
                    fit_view=True,
                    nodeHighlightBehavior=True,
                    highlightColor="#F79767"
                )
                selected_id = agraph(nodes=nodes, edges=edges, config=config)
            else:
                st.warning("í‘œì‹œí•  ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                selected_id = None

        with col2:
            st.markdown("### ğŸ” ìƒì„¸ ì •ë³´")
            if selected_id:
                node_detail = next((n for n in st.session_state.graph_data.get('nodes', []) if str(n.get('id')) == str(selected_id)), None)
                if node_detail:
                    st.success(f"**ëª…ì¹­:** {node_detail.get('label', selected_id)}")
                    st.markdown(f"**ì„¤ëª…:**\n{node_detail.get('desc', 'ì„¤ëª… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')}")
            else:
                st.write("ğŸ’¡ ê·¸ë˜í”„ì—ì„œ ë…¸ë“œë¥¼ í´ë¦­í•˜ì„¸ìš”.")

        st.divider()

        # 3. ì±„íŒ… ì˜ì—­
        st.subheader("ğŸ’¬ í†µí•© ë¶„ì„ ì±„íŒ…")
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ì´ ë¬¸ì„œë“¤ì˜ ê³µí†µì ì´ë‚˜ íŠ¹ì • ìœ ì „ìì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("í†µí•© ë¬¸ì„œ í™•ì¸ ì¤‘..."):
                    try:
                        # ì±„íŒ… ì‹œì—ë„ í†µí•© í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
                        response = model.generate_content(f"ë‹¹ì‹ ì€ ìœ ì „ì²´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í†µí•© ë³´ê³ ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\në‚´ìš©: {st.session_state.full_text[:8000]}\n\nì§ˆë¬¸: {prompt}")
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error(f"ì±„íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")